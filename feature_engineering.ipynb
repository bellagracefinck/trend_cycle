{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea268933",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from io import StringIO\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "d9b53653",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "84e1992a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wordcloud --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "e027b5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install matplotlib --upgrade --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d5d86a",
   "metadata": {},
   "source": [
    "### Read in dataset\n",
    "Data is collected in the data_generation notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fa81daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14551, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>year</th>\n",
       "      <th>seasonyear</th>\n",
       "      <th>designer</th>\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spring</td>\n",
       "      <td>1990</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>azzedine-alaia</td>\n",
       "      <td>An enfilade of stretchy knits in jewel tones w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spring</td>\n",
       "      <td>1990</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>romeo-gigli</td>\n",
       "      <td>Romeo Gigli is having a moment. The designer’s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fall</td>\n",
       "      <td>1990</td>\n",
       "      <td>1990.1</td>\n",
       "      <td>azzedine-alaia</td>\n",
       "      <td>Alaïa worked with pinstripes and other power m...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spring</td>\n",
       "      <td>1991</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>azzedine-alaia</td>\n",
       "      <td>&lt;a href=\"https://www.vogue.com/article/bella-h...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spring</td>\n",
       "      <td>1991</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>comme-des-garcons</td>\n",
       "      <td>“Comme des Garçons,” Rei Kawakubo told &lt;em&gt;Vog...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   season  year  seasonyear           designer  \\\n",
       "0  spring  1990      1990.0     azzedine-alaia   \n",
       "1  spring  1990      1990.0        romeo-gigli   \n",
       "2    fall  1990      1990.1     azzedine-alaia   \n",
       "3  spring  1991      1991.0     azzedine-alaia   \n",
       "4  spring  1991      1991.0  comme-des-garcons   \n",
       "\n",
       "                                                text  id  \n",
       "0  An enfilade of stretchy knits in jewel tones w...   0  \n",
       "1  Romeo Gigli is having a moment. The designer’s...   1  \n",
       "2  Alaïa worked with pinstripes and other power m...   2  \n",
       "3  <a href=\"https://www.vogue.com/article/bella-h...   3  \n",
       "4  “Comme des Garçons,” Rei Kawakubo told <em>Vog...   4  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('complete.csv').drop(['Unnamed: 0','Unnamed: 0.3','Unnamed: 0.2','Unnamed: 0.1', 'Unnamed: 0.4'], axis = 1)\n",
    "print(data.shape)\n",
    "# Create the 'seasonyear' column\n",
    "data['seasonyear'] = data['year'] + data['season'].map({'spring': 0.0, 'fall': 0.1})\n",
    "data['id'] = data.index\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1b4a6dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>year</th>\n",
       "      <th>seasonyear</th>\n",
       "      <th>designer</th>\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5976</th>\n",
       "      <td>spring</td>\n",
       "      <td>2014</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>a-f-vandevorst</td>\n",
       "      <td>\"1998 | 2013,\" A.F. Vandevorst's program notes...</td>\n",
       "      <td>5976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2401</th>\n",
       "      <td>spring</td>\n",
       "      <td>2008</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>zac-posen</td>\n",
       "      <td>\"&lt;em&gt;Days of Heaven&lt;/em&gt;, the Shakers, and the...</td>\n",
       "      <td>2401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6133</th>\n",
       "      <td>spring</td>\n",
       "      <td>2014</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>jasmin-shokrian</td>\n",
       "      <td>\"&lt;em&gt;Je pars habiter à Los Angeles,&lt;/em&gt;\" read...</td>\n",
       "      <td>6133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1287</th>\n",
       "      <td>spring</td>\n",
       "      <td>2005</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>emilio-pucci</td>\n",
       "      <td>\"&lt;em&gt;Je suis realiste; c'est moi. Je ne suis p...</td>\n",
       "      <td>1287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10475</th>\n",
       "      <td>spring</td>\n",
       "      <td>2019</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>azzedine-alaia</td>\n",
       "      <td>\"&lt;em&gt;The past is clear; the future is obscure....</td>\n",
       "      <td>10475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8405</th>\n",
       "      <td>fall</td>\n",
       "      <td>2016</td>\n",
       "      <td>2016.1</td>\n",
       "      <td>no-6</td>\n",
       "      <td>“Your mom could wear it . . . you could wear i...</td>\n",
       "      <td>8405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9571</th>\n",
       "      <td>spring</td>\n",
       "      <td>2018</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>celine</td>\n",
       "      <td>“You’re all I need to get by.” Method Man feat...</td>\n",
       "      <td>9571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7829</th>\n",
       "      <td>spring</td>\n",
       "      <td>2016</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>gareth-pugh</td>\n",
       "      <td>“You’re so money.” Recall, if you will, that u...</td>\n",
       "      <td>7829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13985</th>\n",
       "      <td>spring</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>marni</td>\n",
       "      <td>“‘Why am I here?’ All the time I’ve been think...</td>\n",
       "      <td>13985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9638</th>\n",
       "      <td>spring</td>\n",
       "      <td>2018</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>fenty-puma</td>\n",
       "      <td>‪Rihanna’s Instagram handle is BadGalRiRi for ...</td>\n",
       "      <td>9638</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14261 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       season  year  seasonyear         designer  \\\n",
       "5976   spring  2014      2014.0   a-f-vandevorst   \n",
       "2401   spring  2008      2008.0        zac-posen   \n",
       "6133   spring  2014      2014.0  jasmin-shokrian   \n",
       "1287   spring  2005      2005.0     emilio-pucci   \n",
       "10475  spring  2019      2019.0   azzedine-alaia   \n",
       "...       ...   ...         ...              ...   \n",
       "8405     fall  2016      2016.1             no-6   \n",
       "9571   spring  2018      2018.0           celine   \n",
       "7829   spring  2016      2016.0      gareth-pugh   \n",
       "13985  spring  2023      2023.0            marni   \n",
       "9638   spring  2018      2018.0       fenty-puma   \n",
       "\n",
       "                                                    text     id  \n",
       "5976   \"1998 | 2013,\" A.F. Vandevorst's program notes...   5976  \n",
       "2401   \"<em>Days of Heaven</em>, the Shakers, and the...   2401  \n",
       "6133   \"<em>Je pars habiter à Los Angeles,</em>\" read...   6133  \n",
       "1287   \"<em>Je suis realiste; c'est moi. Je ne suis p...   1287  \n",
       "10475  \"<em>The past is clear; the future is obscure....  10475  \n",
       "...                                                  ...    ...  \n",
       "8405   “Your mom could wear it . . . you could wear i...   8405  \n",
       "9571   “You’re all I need to get by.” Method Man feat...   9571  \n",
       "7829   “You’re so money.” Recall, if you will, that u...   7829  \n",
       "13985  “‘Why am I here?’ All the time I’ve been think...  13985  \n",
       "9638   ‪Rihanna’s Instagram handle is BadGalRiRi for ...   9638  \n",
       "\n",
       "[14261 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.fillna('drop')\n",
    "data = data[data['text']!= 'drop']\n",
    "data.sort_values('text')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e275b5c0",
   "metadata": {},
   "source": [
    "### Text processing\n",
    "\n",
    "In this step, the text is tokenized, then filtered to exclude html tags, designer names, names of individuals, and stopwords.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a968d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "from gensim.parsing import preprocess_string\n",
    "from unidecode import unidecode\n",
    "\n",
    "designer_names = []\n",
    "for name in [designer.split('-') for designer in data['designer'].unique()]:\n",
    "    for i in range(len(name)):\n",
    "        designer_names.append(name[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f40857e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>raw_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>An</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>enfilade</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>stretchy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>knits</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id raw_tokens\n",
       "0   0         An\n",
       "0   0   enfilade\n",
       "0   0         of\n",
       "0   0   stretchy\n",
       "0   0      knits"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['raw_tokens'] = [word_tokenize(sentence) for sentence in data['text']]\n",
    "raw_tokens = (data[['id','raw_tokens']].explode('raw_tokens'))\n",
    "raw_tokens.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fde15cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5767670194307963\n"
     ]
    }
   ],
   "source": [
    "# creating list of people (proper nouns) mentioned in all collection reviews\n",
    "from nltk.tag import StanfordNERTagger\n",
    "import time\n",
    "from nltk import pos_tag, word_tokenize\n",
    "\n",
    "jar = 'stanford/stanford-ner-4.2.0.jar'\n",
    "model = 'stanford/classifiers/english.all.3class.distsim.crf.ser.gz'\n",
    "\n",
    "st = StanfordNERTagger(model, jar) \n",
    "\n",
    "start = time.time()\n",
    "text = list(raw_tokens['raw_tokens'].unique())\n",
    "people = [word[0] for word in st.tag(text) if word[1] == 'PERSON']\n",
    "end = time.time()\n",
    "print((end-start)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6a30db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns = ['raw_tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0a266e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(sentence):\n",
    "    # clean text\n",
    "    clean_text = bs(sentence, \"html.parser\").get_text()\n",
    "    clean_text = re.sub(r\"http\\S+\", \"\", clean_text)\n",
    "    tokens = word_tokenize(clean_text)\n",
    "    \n",
    "    # filter out all names of people, punctuation, stopwords\n",
    "    tokens = [word for word in tokens if word not in people]\n",
    "    tokens = [word for word in tokens if word not in string.punctuation]\n",
    "    tokens = [word for word in tokens if word not in stopwords.words('english')]\n",
    "    tokens = [unidecode(word) for word in tokens]\n",
    "    tokens = [word for word in tokens if word.lower() not in designer_names]\n",
    "    preprocessed_tokens = preprocess_string(' '.join(tokens))\n",
    "    return ' '.join(preprocessed_tokens)\n",
    "\n",
    "start = time.time()\n",
    "data['preprocessed_sentences'] = [preprocess(sentence) for sentence in data['text']]\n",
    "end = time.time()\n",
    "print(end-start, 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1af645",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Preprocessing took',((end-start)/60), 'minutes and', ((end-start)/60-(end-start)//60)*60, 'seconds.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86de848",
   "metadata": {},
   "source": [
    "### Creation of designer information table\n",
    "- designer name\n",
    "- total # of collections\n",
    "- first season\n",
    "- consistency\n",
    "- prevalence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d752a20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "designer_freq = pd.DataFrame.from_dict(data['designer'].value_counts().to_dict(), orient = 'index').reset_index()\n",
    "designer_freq.columns = ['designer', 'collections']\n",
    "designer_freq.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152b1304",
   "metadata": {},
   "source": [
    "### Creation of calculated metrics\n",
    "- *consistency*: The total number of collections made by designer/total # of seasons since the designer’s initial season (inclusive of first season)\n",
    "- *prevalence*: An adapted version of the consistency metric that penalizes designers who have few collections. This was put in place for two reasons - 1) to penalize designers with high consistency values as a result of having only been around for a short period of time (ex: a designer whose first collection was in the most recent season has a consistency value of 1.0) and 2) to further penalize designers who have low consistency and few collections. I created the prevalence formula using a **penalty term**, $α$.\n",
    "    - α comes in several forms, listed here in order from least to most severe:\n",
    "        1. $α = \\frac{1}{collections^2}$\n",
    "        2. $α = \\frac{1}{collections}$\n",
    "        3. $α = \\frac{1}{\\sqrt{collections}}$\n",
    "        4. $α = \\frac{1}{\\sqrt[3]{collections}}$\n",
    "    - This helps to ensure that designers who have only been in the most recent season (consistency = 1) are not weighted equally with designers who have high consistency values after having been around for many years\n",
    "\n",
    "In my final analysis, I used the third form of $α$, $α = \\frac{1}{\\sqrt{collections}}$, as it penalized the brand new designers with high consistency values without limiting high prevalence values to exclusively the oldest, most established designers. \n",
    "\n",
    "The metric is then calculated as $prevalence = consistency - \\frac{1}{\\sqrt{collections}}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673f68ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_seasons = data.groupby('designer')['seasonyear'].min().to_dict()\n",
    "designer_freq['first_season'] = designer_freq['designer'].map(first_seasons)\n",
    "total_seasons = len(data['seasonyear'].unique())\n",
    "sample = designer_freq.copy()\n",
    "\n",
    "cons = []\n",
    "\n",
    "prev_1 = []\n",
    "prev_2 = []\n",
    "prev_3 = []\n",
    "prev_4 = []\n",
    "\n",
    "for designer in designer_freq['designer']:\n",
    "    first_season = float(designer_freq[designer_freq['designer']==designer]['first_season'].iloc[0])\n",
    "    seasons_since = len(data['seasonyear'].unique()[data['seasonyear'].unique() >= first_season])\n",
    "    collections = float(designer_freq[designer_freq['designer'] == designer]['collections'].iloc[0])\n",
    "    if first_season == 2023.1:\n",
    "        seasons_since = 1\n",
    "    elif first_season == 2023.0:\n",
    "        seasons_since = 2\n",
    "    cons.append(collections/seasons_since)\n",
    "    prev_1.append(collections/seasons_since - (1/collections)**2)\n",
    "    prev_2.append(collections/seasons_since - 1/collections)\n",
    "    prev_3.append(collections/seasons_since - 1/np.sqrt(collections))\n",
    "    prev_4.append(collections/seasons_since - 1/collections**(1/3))\n",
    "    \n",
    "    \n",
    "designer_freq['consistency'] = cons\n",
    "designer_freq['prev_1'] = prev_1\n",
    "designer_freq['prev_2'] = prev_2\n",
    "designer_freq['prev_3'] = prev_3\n",
    "designer_freq['prev_4'] = prev_4\n",
    "\n",
    "designer_freq.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819f09f3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "pp = sns.pairplot(data=designer_freq, hue = 'first_season', palette = 'viridis',\n",
    "                  x_vars=['collections'],\n",
    "                  y_vars=['consistency','prev_1', 'prev_2', 'prev_3', 'prev_4'], height = 4)\n",
    "pp.fig.suptitle(\"Prevalence penalty terms\")\n",
    "plt.tight_layout(pad=3.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df51de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "designer_freq['prevalence'] = designer_freq['prev_2']\n",
    "designers = designer_freq[['designer', 'collections', 'first_season', 'consistency', 'prevalence']].copy()\n",
    "\n",
    "percentile_values = [np.percentile(designer_freq['prevalence'], x) for x in [20, 40, 60, 80, 90]]\n",
    "class_boundaries = list(percentile_values) + [np.inf]\n",
    "print(class_boundaries)\n",
    "\n",
    "def assign_class(value):\n",
    "    for i, boundary in enumerate(class_boundaries):\n",
    "        if value <= boundary:\n",
    "            return i\n",
    "\n",
    "# Apply assign_class function to calculate class for each designer\n",
    "designers['class'] = designers['prevalence'].apply(assign_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3dd2c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "designers.groupby('class')[['first_season', 'collections']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfcc8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "designers.sort_values('consistency', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2258491",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "designers.sort_values('prevalence', ascending = False)[120:140]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946f19c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "consistency_dict = dict(zip(designers['designer'],designers['consistency']))\n",
    "prev_dict = dict(zip(designers['designer'],designers['prevalence']))\n",
    "class_dict = dict(zip(designers['designer'],designers['class']))\n",
    "data['consistency'] = data['designer'].map(consistency_dict)\n",
    "data['prevalence'] = data['designer'].map(prev_dict)\n",
    "data['class'] = data['designer'].map(class_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57ae71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "designers['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "2addc6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "designers.to_csv('designers.csv')\n",
    "data.to_csv('collections.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
